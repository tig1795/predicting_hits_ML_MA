{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 5 - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Kapitelübersicht <a class=\"anchor\" id=\"5-1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Evaluation eines Klassifizierungsverfahren ist notwendig, um es bewerten und mit anderen Klassifizierungsverfahren vergleichen zu können. In diesem Kapitel gehen wir auf die verschiedenen Metriken und Ansätze ein, mit der wir ein Klassifizierungsverfahren bewerten können. Zuletzt werden wir dann ein Evaluationsverfahren für die restliche Tutorialreihe festlegen.\n",
    "\n",
    "<b>Abschnittsübersicht</b><br>\n",
    "\n",
    "[5.1. Kapitelübersicht](#5-1)<br>\n",
    "[5.2. Trainings- und Testdatensatz](#5-2)<br>\n",
    "[5.3. Classification accuracy](#5-3)<br>\n",
    "[5.4. Confusion Matrix](#5-4)<br>\n",
    "[5.5. Der F1-Score](#5-5)<br>\n",
    "[5.6. k-fold cross-validation](#5-6)<br>\n",
    "[5.7. Evaluation in der Tutorialreihe](#5-7)<br>\n",
    "[5.8. Mögliche Fehler](#5-8)<br>\n",
    "\n",
    "Am Ende dieses Kapitel werden wir folgende Themen behandelt und/oder vertieft haben:\n",
    "- Aufteilung in Trainings- und Testdatensätze \n",
    "- Aufteilung in Trainings-, Validierungs- und Testdatensätze\n",
    "- Classification accuracy\n",
    "- Visualisierung einer Confusion Matrix\n",
    "- Der F-Score\n",
    "- k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Trainings- und Testdatensatz <a class=\"anchor\" id=\"5-2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei den meisten Evaluationstechniken wird eine Bewertung für eine Textklassifikation berechnet, indem der Datensatz in einen <b>Trainings- und Testdatensatz</b> (auch Evaluationsdatensatz genannt) unterteilt wird. Das Klassifikationsverfahren wird dabei wie gewohnt auf den Trainingsdatensatz angewendet. Beim Testdatensatz werden die <i>Labels/ Klassen</i> (im unseren Fall die Wikipediakategorien) entfernt und das Klassifikationsmodell muss diese Labels generieren. Die generierten Labels werden dann mit den tatsächlichen Labels des Testdatensatzes verglichen. Basierend darauf wird ein <b>score</b> (deutsch: Punktzahl) berechnet, der angibt, wie gut ein erlerntes Klassifikationsmodell neue Daten klassifizieren kann.<br>\n",
    "Der Testdatensatz muss dabei das gleiche Format wie der Trainingsdatensatz haben. Inhaltlich muss sich der Testdatensatz jedoch von dem Trainingsdatensatz unterscheiden, d.h. es sollen keine Teildatensätze im Testdatensatz wiederverwendet werden. Im schlimmsten Fall würden wir den Trainingsdatensatz einfach als Testdatensatz wiederverwenden und das Klassifikationsmodell würde sich einfach die Datensätze \"merken\". Der zentrale und wichtige Schritt der Verallgemeinerung entfällt. Dies würde zu einem sehr guten <b>Score</b> führen, der jedoch verfälscht ist. Bei der Voraussage von neuen Datensätze würde unser Klassifikationsmodell dann vermutlich sehr schlechte Voraussagen treffen, obwohl der Score sehr gut war."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden des Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>pos</th>\n",
       "      <th>year</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>flesch_index</th>\n",
       "      <th>num_lines</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>num_dupes</th>\n",
       "      <th>number_of_tokens</th>\n",
       "      <th>number_of_types</th>\n",
       "      <th>decades</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>POS_tags</th>\n",
       "      <th>POS</th>\n",
       "      <th>value</th>\n",
       "      <th>Hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here she comes  mmm  just like an angelseems ...</td>\n",
       "      <td>['alternative rock', 'glam metal', 'hard rock']</td>\n",
       "      <td>405.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1990</td>\n",
       "      <td>4.8</td>\n",
       "      <td>89.75</td>\n",
       "      <td>43</td>\n",
       "      <td>{'neg': 0.156, 'neu': 0.714, 'pos': 0.131, 'co...</td>\n",
       "      <td>(Can't Live Without Your) Love And Affection</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>323.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1990s</td>\n",
       "      <td>here she come mmm just like an angelseem like...</td>\n",
       "      <td>['_SP', 'RB', 'PRP', 'VBZ', '_SP', 'FW', '_SP'...</td>\n",
       "      <td>missingcan't outside hard mindbut nothing chan...</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look into my eyes  you will seewhat you mean t...</td>\n",
       "      <td>['acoustic rock', 'adult contemporary', 'album...</td>\n",
       "      <td>258.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>4.4</td>\n",
       "      <td>107.69</td>\n",
       "      <td>36</td>\n",
       "      <td>{'neg': 0.14100000000000001, 'neu': 0.708, 'po...</td>\n",
       "      <td>(Everything I Do) I Do It For You</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>233.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1990s</td>\n",
       "      <td>look into my eye you will seewhat you mean to...</td>\n",
       "      <td>['VB', 'IN', 'PRP$', 'NNS', '_SP', 'PRP', 'MD'...</td>\n",
       "      <td>worth worth worth other worth worth heart soul...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can't get no satisfactioni can't get no sati...</td>\n",
       "      <td>['blues', 'blues rock', 'britannique', 'britis...</td>\n",
       "      <td>296.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1965</td>\n",
       "      <td>4.8</td>\n",
       "      <td>106.67</td>\n",
       "      <td>37</td>\n",
       "      <td>{'neg': 0.126, 'neu': 0.667, 'pos': 0.20800000...</td>\n",
       "      <td>(I Can't Get No) Satisfaction</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>260.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1960s</td>\n",
       "      <td>i ca n't get no satisfactioni ca n't get no s...</td>\n",
       "      <td>['PRP', 'MD', 'RB', 'VB', 'DT', 'NN', 'MD', 'R...</td>\n",
       "      <td>satisfaction'cause nowhen drivin useless satis...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh  i  i just died in your arms tonightit must...</td>\n",
       "      <td>['classic pop and rock']</td>\n",
       "      <td>372.6</td>\n",
       "      <td>32</td>\n",
       "      <td>1987</td>\n",
       "      <td>4.4</td>\n",
       "      <td>99.23</td>\n",
       "      <td>45</td>\n",
       "      <td>{'neg': 0.164, 'neu': 0.766, 'pos': 0.07, 'com...</td>\n",
       "      <td>(I Just) Died In Your Arms</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>310.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1980s</td>\n",
       "      <td>oh i i just die in your arm tonightit must 'v...</td>\n",
       "      <td>['UH', '_SP', 'PRP', '_SP', 'PRP', 'RB', 'VBD'...</td>\n",
       "      <td>easy thisher final many long hot easy gonei to...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your love is fadin'  i feel it fadeah  your lo...</td>\n",
       "      <td>['american', 'psychedelic rock', 'psychedelic ...</td>\n",
       "      <td>251.1</td>\n",
       "      <td>55</td>\n",
       "      <td>1970</td>\n",
       "      <td>4.4</td>\n",
       "      <td>99.23</td>\n",
       "      <td>31</td>\n",
       "      <td>{'neg': 0.148, 'neu': 0.795, 'pos': 0.057, 'co...</td>\n",
       "      <td>(I Know) I'm Losing You</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>203.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1970s</td>\n",
       "      <td>your love is fadin ' i feel it fadeah your lo...</td>\n",
       "      <td>['PRP$', 'NN', 'VBZ', 'VBG', \"''\", '_SP', 'PRP...</td>\n",
       "      <td>cancan eyesa hearted worried love love love wo...</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>maybe i need some rehabor maybe just need some...</td>\n",
       "      <td>['a filk artist', 'dance', 'dance-pop', 'elect...</td>\n",
       "      <td>459.9</td>\n",
       "      <td>28</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.4</td>\n",
       "      <td>99.23</td>\n",
       "      <td>63</td>\n",
       "      <td>{'neg': 0.048, 'neu': 0.509, 'pos': 0.443, 'co...</td>\n",
       "      <td>Your Love Is My Drug</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>383.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2010s</td>\n",
       "      <td>mayb i need some rehabor mayb just need some ...</td>\n",
       "      <td>['RB', 'PRP', 'VBP', 'DT', 'NN', 'RB', 'RB', '...</td>\n",
       "      <td>sick desperate hard loveyour loveyour own hazy...</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>your mama don't dance andyour daddy don't rock...</td>\n",
       "      <td>['american', 'rock-pop']</td>\n",
       "      <td>290.7</td>\n",
       "      <td>53</td>\n",
       "      <td>1973</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.24</td>\n",
       "      <td>43</td>\n",
       "      <td>{'neg': 0.042, 'neu': 0.9390000000000001, 'pos...</td>\n",
       "      <td>Your Mama Don't Dance</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>250.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1970s</td>\n",
       "      <td>your mama do n't danc andyour daddi do n't ro...</td>\n",
       "      <td>['PRP$', 'NN', 'VBP', 'RB', 'VB', 'DT', 'NN', ...</td>\n",
       "      <td>rollwhen old sinthere rollwhen backseatwhere n...</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>every day there's something newhoney  to keep ...</td>\n",
       "      <td>['american', 'death by gun', 'death by murder'...</td>\n",
       "      <td>230.4</td>\n",
       "      <td>32</td>\n",
       "      <td>1967</td>\n",
       "      <td>5.2</td>\n",
       "      <td>88.74</td>\n",
       "      <td>22</td>\n",
       "      <td>{'neg': 0.008, 'neu': 0.651, 'pos': 0.341, 'co...</td>\n",
       "      <td>Your Precious Love</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>182.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1960s</td>\n",
       "      <td>everi day there 's someth newhoney to keep me...</td>\n",
       "      <td>['DT', 'NN', 'EX', 'VBZ', 'NN', 'NN', '_SP', '...</td>\n",
       "      <td>much itheaven abovewhoa precious abovewhoa pre...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>once upon a timeonce when you were minei remem...</td>\n",
       "      <td>['art rock', 'baroque pop', 'british', 'classi...</td>\n",
       "      <td>283.5</td>\n",
       "      <td>91</td>\n",
       "      <td>1986</td>\n",
       "      <td>3.6</td>\n",
       "      <td>92.80</td>\n",
       "      <td>46</td>\n",
       "      <td>{'neg': 0.029, 'neu': 0.806, 'pos': 0.164, 'co...</td>\n",
       "      <td>Your Wildest Dreams</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>226.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1980s</td>\n",
       "      <td>onc upon a timeonc when you were minei rememb...</td>\n",
       "      <td>['RB', 'IN', 'DT', 'NN', 'WRB', 'PRP', 'VBD', ...</td>\n",
       "      <td>wildest new wildest youi wildest timeonce mine...</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>just tell me what you've got to say to me i've...</td>\n",
       "      <td>['asian', 'british', 'british asian', 'english...</td>\n",
       "      <td>303.3</td>\n",
       "      <td>65</td>\n",
       "      <td>1997</td>\n",
       "      <td>4.8</td>\n",
       "      <td>106.67</td>\n",
       "      <td>36</td>\n",
       "      <td>{'neg': 0.05, 'neu': 0.842, 'pos': 0.108, 'com...</td>\n",
       "      <td>Your Woman</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>279.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1990s</td>\n",
       "      <td>just tell me what you 've got to say to me i ...</td>\n",
       "      <td>['RB', 'VB', 'PRP', 'WP', 'PRP', 'VBP', 'VBN',...</td>\n",
       "      <td>unkind high marxist true right same charming h...</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3790 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyrics  \\\n",
       "0      here she comes  mmm  just like an angelseems ...   \n",
       "1     look into my eyes  you will seewhat you mean t...   \n",
       "2     i can't get no satisfactioni can't get no sati...   \n",
       "3     oh  i  i just died in your arms tonightit must...   \n",
       "4     your love is fadin'  i feel it fadeah  your lo...   \n",
       "...                                                 ...   \n",
       "3785  maybe i need some rehabor maybe just need some...   \n",
       "3786  your mama don't dance andyour daddy don't rock...   \n",
       "3787  every day there's something newhoney  to keep ...   \n",
       "3788  once upon a timeonce when you were minei remem...   \n",
       "3789  just tell me what you've got to say to me i've...   \n",
       "\n",
       "                                                  genre  num_syllables  pos  \\\n",
       "0       ['alternative rock', 'glam metal', 'hard rock']          405.0   27   \n",
       "1     ['acoustic rock', 'adult contemporary', 'album...          258.3    1   \n",
       "2     ['blues', 'blues rock', 'britannique', 'britis...          296.1    3   \n",
       "3                              ['classic pop and rock']          372.6   32   \n",
       "4     ['american', 'psychedelic rock', 'psychedelic ...          251.1   55   \n",
       "...                                                 ...            ...  ...   \n",
       "3785  ['a filk artist', 'dance', 'dance-pop', 'elect...          459.9   28   \n",
       "3786                           ['american', 'rock-pop']          290.7   53   \n",
       "3787  ['american', 'death by gun', 'death by murder'...          230.4   32   \n",
       "3788  ['art rock', 'baroque pop', 'british', 'classi...          283.5   91   \n",
       "3789  ['asian', 'british', 'british asian', 'english...          303.3   65   \n",
       "\n",
       "      year  fog_index  flesch_index  num_lines  \\\n",
       "0     1990        4.8         89.75         43   \n",
       "1     1991        4.4        107.69         36   \n",
       "2     1965        4.8        106.67         37   \n",
       "3     1987        4.4         99.23         45   \n",
       "4     1970        4.4         99.23         31   \n",
       "...    ...        ...           ...        ...   \n",
       "3785  2010        4.4         99.23         63   \n",
       "3786  1973        4.0        100.24         43   \n",
       "3787  1967        5.2         88.74         22   \n",
       "3788  1986        3.6         92.80         46   \n",
       "3789  1997        4.8        106.67         36   \n",
       "\n",
       "                                              sentiment  \\\n",
       "0     {'neg': 0.156, 'neu': 0.714, 'pos': 0.131, 'co...   \n",
       "1     {'neg': 0.14100000000000001, 'neu': 0.708, 'po...   \n",
       "2     {'neg': 0.126, 'neu': 0.667, 'pos': 0.20800000...   \n",
       "3     {'neg': 0.164, 'neu': 0.766, 'pos': 0.07, 'com...   \n",
       "4     {'neg': 0.148, 'neu': 0.795, 'pos': 0.057, 'co...   \n",
       "...                                                 ...   \n",
       "3785  {'neg': 0.048, 'neu': 0.509, 'pos': 0.443, 'co...   \n",
       "3786  {'neg': 0.042, 'neu': 0.9390000000000001, 'pos...   \n",
       "3787  {'neg': 0.008, 'neu': 0.651, 'pos': 0.341, 'co...   \n",
       "3788  {'neg': 0.029, 'neu': 0.806, 'pos': 0.164, 'co...   \n",
       "3789  {'neg': 0.05, 'neu': 0.842, 'pos': 0.108, 'com...   \n",
       "\n",
       "                                             title  ...  difficult_words  \\\n",
       "0     (Can't Live Without Your) Love And Affection  ...               21   \n",
       "1                (Everything I Do) I Do It For You  ...                6   \n",
       "2                    (I Can't Get No) Satisfaction  ...               18   \n",
       "3                       (I Just) Died In Your Arms  ...               26   \n",
       "4                          (I Know) I'm Losing You  ...               18   \n",
       "...                                            ...  ...              ...   \n",
       "3785                          Your Love Is My Drug  ...               26   \n",
       "3786                         Your Mama Don't Dance  ...               12   \n",
       "3787                            Your Precious Love  ...               21   \n",
       "3788                           Your Wildest Dreams  ...               10   \n",
       "3789                                    Your Woman  ...               14   \n",
       "\n",
       "     num_dupes  number_of_tokens  number_of_types  decades  \\\n",
       "0           23             323.0            133.0    1990s   \n",
       "1           12             233.0             95.0    1990s   \n",
       "2           22             260.0             83.0    1960s   \n",
       "3           31             310.0            130.0    1980s   \n",
       "4            3             203.0            104.0    1970s   \n",
       "...        ...               ...              ...      ...   \n",
       "3785        34             383.0            142.0    2010s   \n",
       "3786        25             250.0             91.0    1970s   \n",
       "3787         9             182.0            103.0    1960s   \n",
       "3788        27             226.0             70.0    1980s   \n",
       "3789        20             279.0            125.0    1990s   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0      here she come mmm just like an angelseem like...   \n",
       "1      look into my eye you will seewhat you mean to...   \n",
       "2      i ca n't get no satisfactioni ca n't get no s...   \n",
       "3      oh i i just die in your arm tonightit must 'v...   \n",
       "4      your love is fadin ' i feel it fadeah your lo...   \n",
       "...                                                 ...   \n",
       "3785   mayb i need some rehabor mayb just need some ...   \n",
       "3786   your mama do n't danc andyour daddi do n't ro...   \n",
       "3787   everi day there 's someth newhoney to keep me...   \n",
       "3788   onc upon a timeonc when you were minei rememb...   \n",
       "3789   just tell me what you 've got to say to me i ...   \n",
       "\n",
       "                                               POS_tags  \\\n",
       "0     ['_SP', 'RB', 'PRP', 'VBZ', '_SP', 'FW', '_SP'...   \n",
       "1     ['VB', 'IN', 'PRP$', 'NNS', '_SP', 'PRP', 'MD'...   \n",
       "2     ['PRP', 'MD', 'RB', 'VB', 'DT', 'NN', 'MD', 'R...   \n",
       "3     ['UH', '_SP', 'PRP', '_SP', 'PRP', 'RB', 'VBD'...   \n",
       "4     ['PRP$', 'NN', 'VBZ', 'VBG', \"''\", '_SP', 'PRP...   \n",
       "...                                                 ...   \n",
       "3785  ['RB', 'PRP', 'VBP', 'DT', 'NN', 'RB', 'RB', '...   \n",
       "3786  ['PRP$', 'NN', 'VBP', 'RB', 'VB', 'DT', 'NN', ...   \n",
       "3787  ['DT', 'NN', 'EX', 'VBZ', 'NN', 'NN', '_SP', '...   \n",
       "3788  ['RB', 'IN', 'DT', 'NN', 'WRB', 'PRP', 'VBD', ...   \n",
       "3789  ['RB', 'VB', 'PRP', 'WP', 'PRP', 'VBP', 'VBN',...   \n",
       "\n",
       "                                                    POS     value   Hit  \n",
       "0     missingcan't outside hard mindbut nothing chan...  0.037037  None  \n",
       "1     worth worth worth other worth worth heart soul...  1.000000   Yes  \n",
       "2     satisfaction'cause nowhen drivin useless satis...  0.333333   Yes  \n",
       "3     easy thisher final many long hot easy gonei to...  0.031250  None  \n",
       "4     cancan eyesa hearted worried love love love wo...  0.018182  None  \n",
       "...                                                 ...       ...   ...  \n",
       "3785  sick desperate hard loveyour loveyour own hazy...  0.035714  None  \n",
       "3786  rollwhen old sinthere rollwhen backseatwhere n...  0.018868  None  \n",
       "3787  much itheaven abovewhoa precious abovewhoa pre...  0.031250  None  \n",
       "3788  wildest new wildest youi wildest timeonce mine...  0.010989    No  \n",
       "3789  unkind high marxist true right same charming h...  0.015385  None  \n",
       "\n",
       "[3790 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_csv(\"../../data/CSV/dataset_with_values_no_duplicates.csv\")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teilung in Trainings- und Testdatensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt kodieren und vektorisieren wir unsere Labels und unsere Textdaten. Hierbei wurde der Code dafür etwas abgekürzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "labels = corpus[\"Hit\"]\n",
    "vector = TfidfVectorizer().fit_transform(corpus[\"lyrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun schauen wir uns die Dimensionen der Matrix unseres vektorisierten Textes an. `shape` gibt uns die Dimensionen der Matrix als Tupel `(n,m)` zurück. `n` steht für die Zeilen der Matrix, `m` für die Spalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3790, 68179)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir diese Daten teilen. Da eine Zeile für einen Wikipediaartikel steht, müssen wir uns an der ersten Zahl im Tupel orientieren. Das Verhältnis, wie wir die Daten teilen, soll hier 80% Trainingsdaten und 20% Testdaten sein. Die Bezeichnung \"X\" für die Textdaten und die Bezeichnung \"y\" für die Labels ist typisch und wird auch so von Scikit learn in der Dokumentation genutzt. Dass das \"X\" großgeschrieben wird ist eine Konvention, die zeigt, dass es sich hier um eine Matrix handelt. Vektoren wie \"y\" werden kleingeschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3032, 68179)\n",
      "(3032,)\n",
      "(758, 68179)\n",
      "(758,)\n"
     ]
    }
   ],
   "source": [
    "X_train = vector[:int(3790*0.8)]\n",
    "y_train = labels[:int(3790*0.8)]\n",
    "X_test = vector[int(3790*0.8):]\n",
    "y_test = labels[int(3790*0.8):]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exkurs:</b> Verhältnis von Trainings- und Testdaten <br>\n",
    "    \n",
    "Bei dem Verhältnis von Trainings- und Testdaten sollte der Anteil der Trainingsdaten immer größer sein als die Anzahl der Testdaten. Ein Modell trainiert nur auf den Trainingsdaten, der Testdatensatz dient nur der Evaluation. Bei einem zu kleinen Anteil des Trainingsdatensatzes könnte das Modell zu wenig lernen, obwohl eigentlich genug Daten zur Verfügung stehen würden.<br>\n",
    "Eine typische Aufteilung ist 80% Trainingsdaten und 20% Testdaten. Diese Aufteilung nennt sich auch das <a href=\"https://de.wikipedia.org/wiki/Paretoprinzip\">Paretoprinzip</a>. Der KI-Experte Andrew Ng empfiehlt für sehr große Korpora (ab etwa einer Millionen Datensätze) eine Aufteilung von 98/2 oder sogar 99.5/0.5. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Einteilung gibt es eine von Scikit learn integrierte Funktion `train_test_split`, die die Daten in zufällige Trainings- und Testdatensätze unterteilt. Dort kann man das Verhältnis des Trainings- und Testdatensatzes (`train_size`, `test_size`) angeben, die einzelnen Daten mischen, bevor sie geteilt werden (`shuffle=False`) oder einen Seed für den Zufallsgenerator setzen (`random_state`). Der Parameter `train_size` muss nur zwingend angegeben werden, wenn es `test_size` nicht ergänzen soll (also beide zusammen nicht 1.0 ergeben sollen). Im Folgenden wird für die restliche Tutorial-Reihe immer die Zahl \"42\" für den Parameter `random_state` gewählt (außer eine Änderung wird explizit erwähnt), damit die Ergebnisse reproduzierbar sind. Die Zahl selbst ist dabei eigentlich egal, solange sie immer die gleiche ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun setzen wir unsere Daten in unser Klassifizierungsverfahren ein. Anstatt den vektorisierten Daten `vector` und den Labels `labels` übergeben wir nun die vektorisierten Trainingsdaten `X_train` und die Trainingslabels `y_train`. Die Variable `y_pred` enthält die Voraussagen, die das Klassizierungsverfahren anhand der Trainingsdaten auf die Testdaten getroffen hat. Um zu sehen, wieviele Labels richtig zugeordnet wurden, berechnen wir das <b>arithmetische Mittel</b> der Vektoren `y_pred` und `y_test`. Der Mittelwert gibt hier an, wieviel Prozent der Labels richtig zugeordnet wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5237467018469657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "mnb = classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exkurs:</b> Arithmetisches Mittel <br>\n",
    "    \n",
    "Das <b>Arithmetische Mittel</b> ist eines der drei Varianten des <b>Mittelwerts</b>. Es wird berechnet, indem alle gegebenen Werte durch die Anzahl der Werte geteilt werden.<br><br>\n",
    "\n",
    "$ \\overline{x} = \\frac{1}{n} \\sum\\nolimits_{i=1}^n x_i = \\frac{x_1 + x_2 + ... + x_n}{n} $ \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Classification accuracy <a class=\"anchor\" id=\"5-3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die <b>Classification accuracy</b> (oder auch nur <b>accuracy</b>) ist ein Maß zur Bewertung von Klassifikationsverfahren. Sie wird folgendermaßen berechnet:<br>\n",
    "\n",
    "<u>Formel (allgemein)</u>:<br>\n",
    "$  \\text{Classification accuracy} = \\frac{\\text{Anzahl der korrekten Voraussagen}}{\\text{Gesamtanzahl aller Voraussagen}} $<br>\n",
    "\n",
    "<u>Formel (mathematisch)</u>:<br>\n",
    "$\\text{Classification accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)$ [<sup>1</sup>](#fn1)<br><br>\n",
    "\n",
    "Die Formel scheint auf dem ersten Blick dem <b>arithmetischen Mittel</b> zu ähneln, hat aber einen entscheidenden Unterschied:\n",
    "- Das <b>Arithmetische Mittel</b> ist ein Maß, das den <i>Durchschnitt</i> einer Reihe von Zahlen angibt.\n",
    "- Die <b>Classification Accuracy</b> ist ein Maß, das zwei Zahlenreihen miteinander <i>vergleicht</i> und angibt, wie hoch die Übereinstimmung ist.\n",
    "\n",
    "<u>Beispiel</u>:<br>\n",
    "Zwei kodierte Labelvektoren werden miteinander verglichen. Es soll berechnet werden, wieviele gemeinsame Labels die beiden Vektoren haben. Haben sie ein gemeinsames Label, erhält die Schnittstelle den Wert \"1\", ansonsten eine \"0\".<br>\n",
    "$ v_1 = (1, 1, 2, 5, 3, 4, 4) $<br>\n",
    "$ v_2 = (1, 2, 2, 5, 4, 4, 3) $<br>\n",
    "\n",
    "$ \\text{Alle Voraussagen:}\\ 1==1,\\ 1==2,\\ 2==2,\\ 5==5,\\ 3==4,\\ 4==4,\\ 4==3 $<br>\n",
    "$ \\text{Anzahl der korrekten Voraussagen:}\\ 1 + 0 + 1 + 1 + 0 + 1 + 0 = 4 $<br>\n",
    "$ \\text{Gesamtanzahl aller Voraussagen:}\\ 7 $<br>\n",
    "\n",
    "$ \\text{Classification accuracy} = \\frac{4}{7} = 0.57$<br>\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn1\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">1</sup> &nbsp; Siehe <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\">https://scikit-learn.org/stable/modules/model_evaluation.html</a> (abgerufen am 03.09.2019).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit learn wird die Classification accuracy folgendermaßen berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5237467018469657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Classification accuracy ist nur bedingt als Evaluationsmaß nützlich. Wichtige Details, die zum besseren Verständnis der Leistung eines Klassifikationsmodell nötig wären, werden ausgeblendet. Dies wird in zwei Fällen deutlich:<br>\n",
    "1. Sogenannte <b>unausgegliche Datensätze</b> (englisch: imbalanced datasets), bei denen die Daten keine gerade Anzahl an Klassen haben, sind problematisch: Ist die Classification accuracy 90%, aber 90 von 100 Datensätzen sind einer Klasse zugeordnet, kann genau die gleiche Genauigkeit auch erreicht werden, wenn man einfach für jeden Datensatz die häufigste Klasse voraussagt.[<sup>2</sup>](#fn2) Die accuracy scheint hoch zu sein, im Hinblick auf die Verteilung der Klassen ist sie jedoch nicht besonders gut.\n",
    "2. Bei der <b>Multiclass classification</b> kann bei einem Ergebnis von z.B. 85% nicht gesagt werden, ob alle Klassen gleich gut vorhergesagt wurden oder ob eine oder zwei Klassen vom Klassifizierungsmodell vernachlässigt wurden.\n",
    " \n",
    "\n",
    "Unser Datensatz ist ausgeglichen, da zu jeder Kategorie gleich viele Artikel gehören (immer genau 200 Artikel). Jedoch benutzen wir Multiclass classification, weshalb die Classification accuracy als Evaluationsmethode für unseren Datensatz nicht uneingeschränkt genutzt werden kann.\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn1\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">2</sup> &nbsp; Dieses Problem wird auch <a href=https://en.wikipedia.org/wiki/Accuracy_paradox>Accuracy paradox</a> genannt. Ein sehr anschauliches Beispiel dafür bietet dieser <a href=\"https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c\">Medium-Artikel</a>.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Confusion Matrix <a class=\"anchor\" id=\"5-4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Möglichkeit, die Ergebnisse der Voraussagen eines Klassifikationsverfahren zu visualisieren, bietet die <b>Confusion Matrix</b> (deutsch: Wahrheitsmatrix). Diese Matrix ist ein spezifisches Tabellenlayout, bei der die Anzahl der korrekten und inkorrekten Vorhersagen mit Zählwerten zusammengefasst und anhand der Klassen aufgeteilt wird.<br>\n",
    "\n",
    "> The confusion matrix shows the ways in which your classification model is confused when it makes predictions.\"[<sup>3</sup>](#fn3) - <i>Jason Brownlee</i>\n",
    "    \n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<span id=\"fn1\" style=\"font-size:8pt; line-height:1\"><sup style=\"font-size:5pt\">3</sup> &nbsp; Siehe den Blogeintrag <a href=\"https://machinelearningmastery.com/confusion-matrix-machine-learning/\">What is a Confusion Matrix in Machine Learning</a>.</span>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Aufgabe:</b> Confusion Matrix für 2 Klassen <br>\n",
    "    \n",
    "Die Aufgabe ist es, den <a href=\"https://machinelearningmastery.com/confusion-matrix-machine-learning/\">Blog-Eintrag</a> von Jason Brownlee über Confusion Matrizen für 2 Klassen zu lesen. Besonders soll dabei auf die <b>True Positives</b>, <b>True Negatives</b>, <b>False Positives</b> und <b>False Negatives</b> geachtet werden. Sollte dies durch den Blog-Eintrag nicht verständlich genug erklärt werden, können folgende Informationsquellen hinzugezogen werden:\n",
    "- Eine gute deutschsprachige Erklärung (für Besitzer des Buches oder für Studierende, bei denen das Buch/E-Book in der Bibliothek verfügbar ist): KLINKE, Harald, \"Information Retrieval\", in: Fotis JANNIDIS/ Hubertus KOHLE/ Malte REHBEIN, Digital Humanities. Eine Einführung, Stuttgart 2017, S. 268-278, 269.\n",
    "- Eine weiterer englischsprachiger Blog-Eintrag: https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "- Der englische Wikipediaartikel zur Confusion Matrix: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Confusion Matrix für mehr als 2 Klassen zu verstehen, soll sie zunächst erzeugt werden. In Scikit learn ist eine Confusion Matrix Visualisierung implementiert, die jedoch nicht besonders anschaulich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 172,   0],\n",
       "       [  0, 397,   0],\n",
       "       [  0, 189,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix[:10] #verkürzte Darstellung, damit der Output nicht zu groß wird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verwenden lieber die Python Visualisierungsbibliothek <b>Seaborn</b> zur Darstellung der Confusion Matrix. Die Funktion <a href=\"https://seaborn.pydata.org/generated/seaborn.heatmap.html\">heatmap</a> erzeugt dabei eine anschaulichere Confusion Matrix. Dafür müssen wir ihr nur ein DataFrame übergeben, welches die Confusion Matrix als Input hat und als Reihen und Spalten die verschiedenen individuellen Kategorienbezeichnungen (hier `classes` genannt) übergeben bekommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Die Original Kategorienbezeichnungen\n",
    "classes = corpus[\"Hit\"].drop_duplicates().tolist()\n",
    "\n",
    "# Ein DataFrame mit den Kategorienbezeichnungen als Reihen und Spalten\n",
    "cnf_df = pd.DataFrame(cnf_matrix, index=classes, columns=classes)\n",
    "    \n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cnf_df, annot=True, cmap=sns.color_palette(\"Blues\"))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die vertikal Achse zeigt die \"wahren\" Kategorien aus dem Testdatensatz an (`y_test`) und die horizontale Achse zeigt die Kategorien an, die von `y_pred` vorausgesagt wurden. Die Diagonale zeigt hier an, welche Kategorien richtig zugeordnet wurden. So wurde \"Album nach Typ\" 46 Mal richtig der Kategorie \"Album nach Typ\" zugeordnet. Man kann hier sehr gut falsche Klassifikationen erkennen. Umso mehr Kategorien einer anderen Kategorie zugeordnet wurden, umso dunkler ist der Farbton. So sticht sofort die fehlerhafte Klassifizierung von \"Herrscher nach Titel\" auf. Nur 16 Mal wurde diese Kategorie richtig klassifiziert, 25 Mal wurde sie fälschlicherweise der Kategorie \"Krieg nach Typ\" zugeordnet. Bei einer idealen Multiclass Confusion Matrix wären die Felder der Diagonalen die einzigen Felder, die nicht aus 0en bestehen würden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Der F1-score <a class=\"anchor\" id=\"5-5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der <b>F1-score</b> oder auch nur <b>F-score</b> (deutsch: F-Maß) ist wie die <b>Classification Accuracy</b> ein Maß zur Bewertung von Klassifikationsverfahren. Es ist das harmonische Mittel zwischen <b>Precision</b> und <b>Recall</b>. Die Precision zeigt an, wie <i>exakt</i> ein Klassifikationsverfahren klassifiziert und der Recall zeigt an, wie <i>vollständig</i> die Klassifizierungen des Klassifikationsverfahren sind. Sie werden folgendermaßen berechnet:<br>\n",
    "\n",
    "$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives}\\ +\\ \\text{False Positives}}$<br>\n",
    "\n",
    "$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives}\\ +\\ \\text{False Negatives}}$<br>\n",
    "\n",
    "Im Falle unserer Confusion Matrix aus dem vorherigen Abschnitt zeigen die Zeilenwerte einer Kategorie die <b>False Positives</b> Werte an und die Spaltenwerte der entsprechenden Kategorie die <b>False Negatives</b> an. Der Wert in der Zelle, bei der die Kategorie der horizontalen und vertikalen Achse gleich ist, ist der <b>True Positive</b>.<br>\n",
    "\n",
    "Setzen wir die Werte einmal für die Kategorie \"Album nach Typ\" ein:<br>\n",
    "\n",
    "$ \\text{Precision}_\\text{Album nach Typ} = \\frac{46}{46\\ +\\ 3} = 0.9387$<br>\n",
    "\n",
    "$ \\text{Recall}_\\text{Album nach Typ} = \\frac{46}{46\\ +\\ 1} = 0.9787$<br>\n",
    "\n",
    "Die Precision und Recall Werte liegen immer zwischen 0 und 1, wobei die Tendenz gegen 0 ein schlechter Precision oder Recall Wert ist und die Tendenz gegen 1 ein guter Precision oder Recall Wert ist.<br>\n",
    "\n",
    "Der <b>F1-score</b> wird folgendermaßen berechnet:<br>\n",
    "\n",
    "$ \\text{F1-score} = 2 \\cdot \\frac{\\text{Precision}\\ \\cdot\\ \\text{Recall}}{\\text{Precision}\\ +\\ \\text{Recall}}$<br>\n",
    "\n",
    "Der F1-score für die Kategorie \"Album nach Typ\" ist also $ 2 \\cdot \\frac{0.9387\\ \\cdot\\ 0.9787}{0.9387\\ +\\ 0.9787} = 2 \\cdot \\frac{0.9187}{1.9174} = 0.9582$<br>\n",
    "\n",
    "Der F1-score hat anders als die Classification Accuracy kein Problem mit unausgeglichen Datensätzen. Obwohl unser Datensatz ausgeglichen ist, werden wir in den folgenden Kapitel trotzdem den F1-score als Bewertungsmaß für unsere Textklassifizierungsverfahren verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementierung in Scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der F1-score wird in Scikit learn mit der Funktion `f1_score` implementiert. Bei einer Multiclass Klassifikation ist der F1-score der durchschnittliche F1-score aller Klassen. Dieser Durchschnitt kann mit dem `average`-Parameter gewichtet werden. <b>Vorsicht</b>: Der Standardwert ist \"binary\", der jedoch nur für eine binäre Klassifikation gedacht ist. Bei einer Multiclass Klassifikation muss der `average`-Parameter immer angegeben werden. Die verschiedenen Parameterwerte sind in der <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\">Dokumentation</a> aufgelistet. Wir haben hier den `micro`-Durchschnitt verwendet und werden diesen auch für die restliche Tutorialreihe verwenden, sofern es nicht anders angegeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der F1-score für die Klassifizierung mit Multinomial Naive Bayes ist 0.5237467018469657.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels = corpus[\"Hit\"]\n",
    "vector  = TfidfVectorizer().fit_transform(corpus[\"lyrics\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "mnb = classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "print(f\"Der F1-score für die Klassifizierung mit Multinomial Naive Bayes ist {str(f1)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn bietet mit dem <b>Classification Report</b> eine Möglichkeit, die einzelnen Precision, Recall und F1-Score Werte für jede einzelne Klasse anzuzeigen. Dort können auch die verschiedenen Average-Parameter (`\"micro\"`, `\"macro\"`, `\"weighted\"`) des F1-scores angesehen und verglichen werden. Sollten die Klassen zuvor mit einem Encoder kodiert worden sein, wird es empfohlen, die Liste der Klassen dem `target_names` Parameter zu übergeben, da die numerische Repräsentation der Klassen nicht unbedingt informativ ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00       172\n",
      "        None       0.52      1.00      0.69       397\n",
      "         Yes       0.00      0.00      0.00       189\n",
      "\n",
      "    accuracy                           0.52       758\n",
      "   macro avg       0.17      0.33      0.23       758\n",
      "weighted avg       0.27      0.52      0.36       758\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classes = corpus[\"Hit\"].drop_duplicates().tolist()\n",
    "print(classification_report(y_test, y_pred))\n",
    "# alternativ\n",
    "# print(classification_report(y_test, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. k-fold cross validation <a class=\"anchor\" id=\"5-6\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die <b>cross validation</b> (deutsch: Kreuzvalidierungsverfahren) ist ein Verfahren zur Bewertung des Umgangs eines Klassifikationsmodells mit ungesehenen Daten, d.h. die wie gut das Klassifikationsmodell anhand eines unabhängigen Datensatzes <i>verallgemeinern</i> kann. Dadurch soll <b>Overfitting</b> vermieden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exkurs:</b> Overfitting und Underfitting <br>\n",
    "    \n",
    "<b>Overfitting</b> (deutsch: Überanpassung) ist eines der zentralen Probleme von Machine Learning. Das Ziel eines Machine Learning Algorithmus ist es, Informationen aus Daten zu lernen und diese Informationen zu <b>verallgemeinern</b>. Schafft es ein Modell nicht zu verallgemeinern, kommt es zu <b>Overfitting</b>. Dies macht sich bei der Evaluierung bemerkbar: Das Modell liefert sehr gute Werte bei den Trainingsdatensätzen, bei den Testdatensätzen jedoch sehr schlechte Werte oder einen Wert, der stark vom Wert des Trainingsdatensatz abweicht.<br>\n",
    "\n",
    "Ein Machine Learning Modell kann auch \"underfitten\". Das Modell hat zu sehr verallgemeinert, weshalb es sein gelerntes \"Wissen\" aus dem Trainingsdatensatz nicht auf den Testdatensatz anwenden kann. \"Overfitting\" und \"Underfitting\" kann mit den verschiedensten Techniken bekämpft werden. Für weitere Informationen zu Over- und Underfitting siehe den <a href=\"https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/\">Blog-Eintrag</a> von Jason Brownlee.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation ist eine Alternative zur Aufteilung des Datensatzes in Trainings- und Testdatensätze, was wir in Abschnitt 5.2 gesehen haben. Bei einer cross validation wird der Datensatz in <i>k</i>-1 Trainingsdatensätze und einen Testdatensatz aufgeteilt. Es wird solange ein neuer Trainingsdurchlauf durchgeführt, bis jeder Teildatensatz (= <i>fold</i>) einmal die Rolle des Testdatensatzes innehatte. Der Wert <i>k</i> gibt die Anzahl der Durchläufe und die Anzahl der Teildatensätze an. Auf dem folgenden Bild ist <i>k</i> = 5.<br><br>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt=\"k-fold cross validation graphic\" style=\"width: 350px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der cross validation haben wir <i>k</i>-scores, die man mit einem <b>Mittelwert</b> oder einer <b>Standardabweichung</b> zusammenfassen kann. Der Ergebniswert zeigt uns, wie zuverlässig unser Klassifikationsmodell neue Daten klassifizieren kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementierung in Scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit learn wird die cross validation mit der Funktion `cross_val_score` implementiert. Dieser Funktion wird der Classifier, die vektorisierten Textdaten und die Labels übergeben. Der Parameter `cv` gibt <i>k</i> an, solange wir ihm einen Integer übergeben. Je größer `cv` ist, desto länger dauert die cross validation. Übliche Parameter sind 3, 5 oder 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5139841012123703"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(classifier, vector, labels, cv=3)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. Evaluation in der Tutorialreihe <a class=\"anchor\" id=\"5-7\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es stellt sich nun die Frage, wie wir die Klassifizierungsverfahren in unserer Tutorialreihe bewerten. Die <b>cross validation</b> ist der Gold Standard für die Performance Evaluierung eines Machine Learning Algorithmus. Anders als im vorherigen Abschnitt werden wir die cross validation nur auf einem Trainingsdatensatz ausführen. Unser Datensatz ist groß genug, um ihn in Trainings- und Testdatensätze zu teilen, ohne dass der Trainingsdatensatz dadurch zu klein wird, um ihn effektiv trainieren zu können. Der Testdatensatz wird mit dem <b>F1-score</b> evaluiert. Nun haben wir jedoch 2 Testdatensätze. Der eine Testdatensatz wird manuell von uns mithilfe von `train_test_split` aus dem Datensatz extrahiert, der andere wird immer wieder von der cross validation erzeugt. Im Bereich des Machine Learning werden deshalb diese beiden Testdatensätze unterschieden. Der <b>Testdatensatz</b> wird erst für die Evaluierung des finalen Modells genutzt. Der <b>Validierungsdatensatz</b> (englisch: validation data) wird zur Evaluierung des Klassifikationsmodells während der Anpassung der Parameter benutzt. Diese Parameter passen wir bei der <b>k-fold cross validation</b> an, weshalb wir eigentlich keinen eigenständigen oder festen Validierungsdatensatz haben, da dieser bei jedem Durchgang neu bestimmt wird. Im Bereich des <b>Deep Learning</b>, ein Thema welches in späteren Kapiteln behandelt wird, werden wir jedoch noch Anwendungen für den Validierungsdatensatz kennen lernen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Aufgabe:</b> Unterschied von Trainings-, Validierungs- und Testdatensätzen <br>\n",
    "    \n",
    "Die Aufgabe ist es, den <a href=\"https://machinelearningmastery.com/difference-test-validation-datasets/\">Blog-Eintrag</a> von Jason Brownlee über den Unterschied von Trainings-, Validierungs- und Testdatensätze zu lesen.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Evaluation eines Klassifikationsverfahren wird in unserer Tutorialreihe folgendermaßen ausgeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Mittelwert der cross validation bei der  Klassifizierung  mit Multinomial Naive Bayes ist 0.514.\n",
      "\n",
      "Der F1-score für die Klassifizierung mit Multinomial Naive Bayes ist 0.524.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "labels = corpus[\"Hit\"]\n",
    "vector  = TfidfVectorizer().fit_transform(corpus[\"lyrics\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "mnb = classifier.fit(X_train, y_train)\n",
    "\n",
    "# cross validation des Trainingsdatensatzes\n",
    "scores = cross_val_score(classifier, vector, labels, cv=3)\n",
    "mean = np.mean(scores)\n",
    "\n",
    "print(\"Der Mittelwert der cross validation bei der  Klassifizierung \" \n",
    "      + f\" mit Multinomial Naive Bayes ist {str(np.around(mean, decimals=3))}.\"\n",
    "      + \"\\n\")\n",
    "\n",
    "\n",
    "# F1-score des Testdatensatzes\n",
    "y_pred = classifier.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"Der F1-score für die Klassifizierung mit Multinomial Naive Bayes ist \"\n",
    "      + f\"{str(np.around(f1, decimals=3))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8. Mögliche Fehler <a class=\"anchor\" id=\"5-8\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainings- und Testdatensätze überschneiden sich, die Aufteilung ist nicht korrekt, z.B. \n",
    "```\n",
    "X_train = vector[:int(6000*0.8)]\n",
    "y_train = labels[:int(6000*0.8)]\n",
    "X_test = vector[int(6000*0.7):]\n",
    "y_test = labels[int(6000*0.7):]\n",
    "```\n",
    "→ Hier würde der Trainingsdatensatz die Artikel von Position 0 bis 4800 aussuchen (also 4800 Artikel) und der Testdatensatz die Artikel von Position 4200 bis 6000 (also 1800 Artikel). 600 Artikel würden sich überschneiden, was das Ergebnis und den Lernprozess verfälschen würde.\n",
    "- `Target is multiclass but average='binary'. Please choose another average setting.` → Ein falscher oder gar kein Average-Parameter wurde beim F1-score für Daten mit mehr als zwei Klassen verwendet. Average-Parameter wie `micro` oder `macro` müssen gewählt werden.\n",
    "- Confusion Matrix Grafik ist zu groß/ zu klein → Werte bei `plt.figure(figsize=(11,11))` verändern\n",
    "- Confusion Matrix Grafik ist unscharf → Bei Importen folgendes hinzufügen:<br>\n",
    "```%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
